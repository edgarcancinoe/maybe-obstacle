{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "044aa663",
   "metadata": {},
   "source": [
    "# Uncertainty-Aware Road Obstacle Identification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e16c6661",
   "metadata": {},
   "source": [
    "## 1. Imports\n",
    "Import necessary libraries like PyTorch, torchvision, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d47c11dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\marce\\3D Objects\\Sapienza\\Computer Vision\\maybe-obstacle\\venv\\Scripts\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe48609",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da946b4",
   "metadata": {},
   "source": [
    "## 2. Globals\n",
    "Define global variables such as paths, batch size, learning rate, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2556745f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CPU\n"
     ]
    }
   ],
   "source": [
    "# Global variables\n",
    "DATASET_PATH = \"./datasets/\"\n",
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 0.001\n",
    "EPOCHS = 50\n",
    "\n",
    "# Select the best available device (CPU, CUDA, or MPS (Metal Performance Shaders for macOS))\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(f\"Using CUDA device: {torch.cuda.get_device_name(0)}\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    print(\"Using MPS (Metal Performance Shaders) device\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Using CPU\")\n",
    "DEVICE = device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa362e7",
   "metadata": {},
   "source": [
    "## 3. Utils\n",
    "Helper functions for visualization, preprocessing, and more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5ae29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def visualize_sample(image, mask):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.title(\"Image\")\n",
    "    plt.imshow(image)\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.title(\"Mask\")\n",
    "    plt.imshow(mask)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b07190be",
   "metadata": {},
   "source": [
    "### 3.1 Utils for Conformal Risk Control"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec61ef6",
   "metadata": {},
   "source": [
    "Miscoverage Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3beb80",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Compute l(Z, Y) = 1 - (# correctly covered pixels) / (# total pixels).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    set_mask : binary tensor, shape [C, H, W]\n",
    "        For every pixel (i,j) and class k: 1 if class k is included in the set S_ij, 0 otherwise.\n",
    "    labels   : int tensor, shape [H, W]\n",
    "        Ground-truth class index per pixel (values in 0 … C-1).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    loss : scalar tensor\n",
    "        Miscoverage rate in the current image (float in [0, 1]).\n",
    "\"\"\"\n",
    "def miscoverage_loss(set_mask: torch.Tensor,  # [C, H, W] 0/1   – predicted set\n",
    "                     labels:    torch.Tensor  # [H, W]       int – ground-truth class indices\n",
    "                     ) -> torch.Tensor:\n",
    "   \n",
    "    C, H, W = set_mask.shape                       # number of classes & image size\n",
    "\n",
    "    # Build a one-hot tensor for the ground-truth mask Y\n",
    "    # gt_mask[k,i,j] = 1 if ground-truth class at (i,j) == k\n",
    "    gt_mask = torch.zeros_like(set_mask)\n",
    "    gt_mask.scatter_(0, labels.unsqueeze(0), 1)     # in-place one-hot\n",
    "\n",
    "    # Pixel is covered if gt class ∈ predicted set\n",
    "    covered = (set_mask * gt_mask).sum(dim=0)       # → [H, W] ∈ {0,1}\n",
    "\n",
    "    # Coverage ratio = mean over all pixels\n",
    "    coverage = covered.float().mean()               # scalar\n",
    "\n",
    "    # Miscoverage loss ℓ = 1 − coverage\n",
    "    return 1.0 - coverage\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7108835c",
   "metadata": {},
   "source": [
    "Least Ambiguous Set-Valued Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90e4bf02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def T_lambda(probs, lam):\n",
    "    # probs: [C, H, W], lam: float ∈ [0,1]\n",
    "    return (probs >= (1 - lam)).float()  # binariza por canal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f1814c",
   "metadata": {},
   "source": [
    "Dichotomic search over the parameter λ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3577ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "We can compute the optimal like this because the Loss is monotonic in lambda\n",
    "-  Lambda is the threshold for binarization in T_lambda\n",
    "-  Alpha is the tolerated risk level\n",
    "-  Eps is the precision for the binary search\n",
    "\"\"\"\n",
    "\n",
    "def binary_search_lambda(probs_list,labels_list,alpha=0.1,eps=1e-3):\n",
    "    left , right = 0.0, 1.0\n",
    "    while right - left > eps:\n",
    "        mid = (left + right) / 2.0\n",
    "        avr_risk = 0.0 \n",
    "        for probs,labels in zip(probs_list,labels_list):\n",
    "            mask = T_lambda(probs, mid)\n",
    "            risk += miscoverage_loss(mask,labels)        \n",
    "        avr_risk += risk / len(probs_list)\n",
    "        if avr_risk < alpha:\n",
    "            right = mid\n",
    "        else:\n",
    "            left = mid\n",
    "    return mid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d8ba0e1",
   "metadata": {},
   "source": [
    "## 4. Data\n",
    "Load and preprocess datasets like Cityscapes, LostAndFound, and Fishyscapes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b06c9692",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for data loading and preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70ceb8f",
   "metadata": {},
   "source": [
    "## 5. Network\n",
    "Define the neural network architecture for semantic segmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5edcde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model architecture here\n",
    "\n",
    "# Lets replicate the Unknown Objectness Scores setup\n",
    "\n",
    "# Load a pretrained DeepLabv3 model with a ResNet-50 backbone\n",
    "model = models.segmentation.deeplabv3_resnet50(pretrained=True)\n",
    "model = model.to(DEVICE)\n",
    "model.eval()  # Set the model to evaluation mode\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "685e0300",
   "metadata": {},
   "source": [
    "### Conformal Risk Control\n",
    "\n",
    "#### Calibration\n",
    "\n",
    "1. Pass the calibration set through the model to get logits\n",
    "2. Convert logits to probabilities using softmax.\n",
    "3. Run binary_search_lambda over the calibration probabilities to find the optimal Lambda\n",
    "\n",
    "#### Implementation\n",
    "1. Pass the test set through the model to get logits and compute softmax\n",
    "2. Use optimal Lambda to get mask\n",
    "3. Visualize the cardinality of the set. (Pixel wise anomaly detection measurement)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c897d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e08b2d10",
   "metadata": {},
   "source": [
    "## 6. Train\n",
    "Implement the training loop, including loss functions and optimizers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0ca15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop and loss computation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db0f6366",
   "metadata": {},
   "source": [
    "## 7. Test\n",
    "Test the trained model and evaluate performance metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def3d94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation metrics and performance analysis"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
